{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Table of contents\n",
    "\n",
    "#### 1. [Package instalation (optional)](#1)\n",
    "#### 2. [Data loading](#2)\n",
    "#### 3. [Feature Engineering](#3)\n",
    "- ##### 3.1. [Outline](#3_1)\n",
    "- ##### 3.2. [Tokenization](#3_2)\n",
    "- ##### 3.3. [Basic word- and sentence-level metrics](#3_3)\n",
    "- ##### 3.4. [Subjectivity and Polarity metrics](#3_4)\n",
    "- ##### 3.5. [Cosine subjectivity between prompt_text and summary](#3_5)\n",
    "- ##### 3.6. [Readability score](#3_6)\n",
    "- ##### 3.7. [Misspelling frequency](#3_7)\n",
    "- ##### 3.8. [Topic overlap](#3_8)\n",
    "- - ##### 3.8.1 [Stopword filtering](#3_8_1)\n",
    "- - ##### 3.8.2 [Lemmatization](#3_8_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.5/121.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Obtaining dependency information for pyyaml>=5.1 from https://files.pythonhosted.org/packages/ec/0d/26fb23e8863e0aeaac0c64e03fd27367ad2ae3f3cccf3798ee98ce160368/PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from transformers) (2023.8.8)\n",
      "Collecting requests (from transformers)\n",
      "  Obtaining dependency information for requests from https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl.metadata\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/a1/e9/80f82aaa756e1345f80baba24af40eda58009560fa5263ff1b2a1ac32e7d/tokenizers-0.14.1-cp311-cp311-macosx_10_7_x86_64.whl.metadata\n",
      "  Downloading tokenizers-0.14.1-cp311-cp311-macosx_10_7_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.3.1 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/22/3d/32f819203115c314391268d69423eb4653e7478e8d5eaf87ae79ce434263/safetensors-0.4.0-cp311-cp311-macosx_10_7_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.4.0-cp311-cp311-macosx_10_7_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from transformers) (4.66.1)\n",
      "Collecting torch>=1.6.0 (from sentence-transformers)\n",
      "  Obtaining dependency information for torch>=1.6.0 from https://files.pythonhosted.org/packages/16/dd/1bf10180ba812afa1aa7427466083d731bc37b9a1157ec929d0cfeef87eb/torch-2.1.0-cp311-none-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading torch-2.1.0-cp311-none-macosx_10_9_x86_64.whl.metadata (24 kB)\n",
      "Collecting torchvision (from sentence-transformers)\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/23/84/46481327771d4f63feb59dd0d9e1cd6a42e985dbd371965f486a5bf9f323/torchvision-0.16.0-cp311-cp311-macosx_10_13_x86_64.whl.metadata\n",
      "  Downloading torchvision-0.16.0-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scikit-learn in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from sentence-transformers) (1.3.1)\n",
      "Requirement already satisfied: scipy in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from sentence-transformers) (1.11.2)\n",
      "Requirement already satisfied: nltk in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers)\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->transformers)\n",
      "  Obtaining dependency information for fsspec>=2023.5.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.7.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.16.4 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting sympy (from torch>=1.6.0->sentence-transformers)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting networkx (from torch>=1.6.0->sentence-transformers)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/f6/eb/5585c96636bbb2755865c31d83a19dd220ef88e716df4659dacb86e009cc/networkx-3.2-py3-none-any.whl.metadata\n",
      "  Downloading networkx-3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: click in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->transformers)\n",
      "  Obtaining dependency information for charset-normalizer<4,>=2 from https://files.pythonhosted.org/packages/ec/e9/5fe55dbe2204271ea8d6e1434af7d2067770364360b1fbeaa9cd4b8b4c47/charset_normalizer-3.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading charset_normalizer-3.3.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers)\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers)\n",
      "  Obtaining dependency information for urllib3<3,>=1.21.1 from https://files.pythonhosted.org/packages/d2/b2/b157855192a68541a91ba7b2bbcb91f1b4faa51f8bae38d8005c034be524/urllib3-2.0.7-py3-none-any.whl.metadata\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers)\n",
      "  Obtaining dependency information for certifi>=2017.4.17 from https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl.metadata\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/duje/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp311-cp311-macosx_10_9_x86_64.whl (187 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.9/187.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.0-cp311-cp311-macosx_10_7_x86_64.whl (439 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.14.1-cp311-cp311-macosx_10_7_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp311-none-macosx_10_9_x86_64.whl (146.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Downloading torchvision-0.16.0-cp311-cp311-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Downloading charset_normalizer-3.3.1-cp311-cp311-macosx_10_9_x86_64.whl (119 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.2-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=b01b76a2b91659cee5c07d11b6aebb2683b26e147b0dcf90eb07a8f16cdbec60\n",
      "  Stored in directory: /Users/duje/Library/Caches/pip/wheels/ff/27/bf/ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, mpmath, urllib3, sympy, safetensors, pyyaml, networkx, idna, fsspec, filelock, charset-normalizer, certifi, torch, requests, torchvision, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "Successfully installed certifi-2023.7.22 charset-normalizer-3.3.1 filelock-3.12.4 fsspec-2023.10.0 huggingface-hub-0.17.3 idna-3.4 mpmath-1.3.0 networkx-3.2 pyyaml-6.0.1 requests-2.31.0 safetensors-0.4.0 sentence-transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.14.1 torch-2.1.0 torchvision-0.16.0 transformers-4.34.1 urllib3-2.0.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install transformers sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train_df = pd.read_csv('../data/summaries_train.csv')\n",
    "prompts_train_df = pd.read_csv('../data/prompts_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prompt_question prompt_title  \\\n",
       "0  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                             summary   content   wording  \n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join the two data frames based on a unique key and drop unnecessary columns\n",
    "joined_df = pd.merge(prompts_train_df, summaries_train_df, on = 'prompt_id')\n",
    "joined_df.drop(['prompt_id', 'student_id'], axis = 1, inplace = True)\n",
    "\n",
    "#rename 'text' column to 'summary'\n",
    "joined_df.rename(columns = {'text' : 'summary'}, inplace=True)\n",
    "\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_1'></a>\n",
    "### 3.1. Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to train the model to predict content and wording scores.\n",
    "\n",
    "• Wording Model  \n",
    "\n",
    "a) Voice\n",
    "\n",
    "Voice in writing refers to the author's distinctive style and tone. In the context of grading student summaries, \"using objective language\" means that the summary should avoid personal opinions, emotional language, or subjective statements. It should be neutral and objective, presenting the facts from the source text without adding the author's own perspective.  \n",
    "\n",
    "b) Paraphrase  \n",
    "\n",
    "Paraphrasing involves restating the information from the source text in a new way, without changing its meaning. A high score in paraphrasing means that the summary effectively conveys the key points of the source text in a concise and clear manner. It should avoid direct copying of sentences from the source.\n",
    "\n",
    "c) Language  \n",
    "\n",
    "This component assesses the quality of the language used in the summary. It considers factors such as vocabulary choice, sentence structure, and grammar. A good summary should use appropriate and varied vocabulary, follow correct grammar rules, and have coherent sentence structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Content Scores: \n",
    "\n",
    "a) Main idea  \n",
    "\n",
    "This aspect evaluates how well the summary captures the primary message or main idea of the source text. A high score means that the summary effectively identifies and conveys the central theme or argument of the source.  \n",
    "\n",
    "b) Details  \n",
    "\n",
    "Details refer to specific information, examples, or evidence from the source text. A good summary should accurately represent these details without omitting crucial information or including irrelevant details. The summary should focus on the most relevant supporting details.  \n",
    "\n",
    "c) Cohesion  \n",
    "\n",
    "Cohesion assesses how well the summary transitions from one idea to the next. It considers the flow of the summary and how well sentences and paragraphs are connected. A high score indicates that the summary has a logical and smooth progression of ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features that could be useful:  \n",
    "\n",
    "• Extract average sentence length, average word length, word count, unique and stopwords percentage from prompt_text and summary and divide to create new feature.  \n",
    "\n",
    "• For each summary calculate subjectivity and emotional tone (polarity).  \n",
    "\n",
    "• Calculate cosine similarity between prompt_text and summary.  \n",
    "\n",
    "• Calculate readability score. \n",
    "\n",
    "• Calculate frequency of misspelled words in student summaries.   \n",
    "\n",
    "• Extract topics from prompt_text, prompt_question and student summaries. Use overlap as a feature.  \n",
    "\n",
    "• Calculate most used 2-grams and 3-grams in prompt_text and summaries and calculate overlap in the 2 categories. Use this as a new feature. \n",
    "\n",
    "• Perform Named Entity Recognition (NER) on prompt_text and summaries, and calculate overlap to access if relevant features are captured.  \n",
    "\n",
    "• Calculate the frequency of transition words in summaries to evaluate cohesion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_2'></a>\n",
    "### 3.2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the 'punkt' resource\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[1, element, of, an, ideal, tragedy, is, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[The, three, elements, of, an, ideal, tragedy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[Aristotle, states, that, an, ideal, tragedy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prompt_question prompt_title  \\\n",
       "0  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                             summary   content   wording  \\\n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181   \n",
       "\n",
       "                           prompt_question_tokenized prompt_title_tokenized  \\\n",
       "0  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "1  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "2  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "\n",
       "                               prompt_text_tokenized  \\\n",
       "0  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "1  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "2  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "\n",
       "                                   summary_tokenized  \n",
       "0  [1, element, of, an, ideal, tragedy, is, that,...  \n",
       "1  [The, three, elements, of, an, ideal, tragedy,...  \n",
       "2  [Aristotle, states, that, an, ideal, tragedy, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_question_tokenized'] = joined_df['prompt_question'].apply(word_tokenize)\n",
    "joined_df['prompt_title_tokenized'] = joined_df['prompt_title'].apply(word_tokenize)\n",
    "joined_df['prompt_text_tokenized'] = joined_df['prompt_text'].apply(word_tokenize)\n",
    "joined_df['summary_tokenized'] = joined_df['summary'].apply(word_tokenize)\n",
    "\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_3'></a>\n",
    "### 3.3. Basic word- and sentence-level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(text):\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_count = len(sentences)\n",
    "    \n",
    "    return sentence_count\n",
    "\n",
    "def count_total_words(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    word_count = len(words)\n",
    "    \n",
    "    return word_count\n",
    "\n",
    "def get_unique_words_percentage(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    unique_words = set(words)\n",
    "    unique_word_count = len(unique_words)\n",
    "    \n",
    "    unique_word_percentage = unique_word_count / len(words)\n",
    "    \n",
    "    return unique_word_percentage    \n",
    "    \n",
    "def get_stopwords_percentage(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    stopwords = [word for word in words if word not in stop and word.isalnum()]\n",
    "\n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    \n",
    "    stopwords_percentage = len(stopwords) / len(words)\n",
    "    \n",
    "    return stopwords_percentage\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence count\n",
    "joined_df['prompt_text_sentence_count'] = joined_df['prompt_text'].apply(count_sentences)\n",
    "joined_df['summary_sentence_count'] = joined_df['summary'].apply(count_sentences)\n",
    "joined_df['sentence_count_ratio'] = joined_df['summary_sentence_count'] / joined_df['prompt_text_sentence_count']\n",
    "\n",
    "#word count\n",
    "joined_df['prompt_text_word_count'] = joined_df['prompt_text'].apply(count_total_words)\n",
    "joined_df['summary_word_count'] = joined_df['summary'].apply(count_total_words)\n",
    "joined_df['word_count_ratio'] = joined_df['summary_word_count'] / joined_df['prompt_text_word_count']\n",
    "\n",
    "#average sentence length\n",
    "joined_df['prompt_text_avg_sentence_length'] = joined_df['prompt_text_word_count'] / joined_df['prompt_text_sentence_count']\n",
    "joined_df['summary_avg_sentence_length'] = joined_df['summary_word_count'] / joined_df['summary_sentence_count']\n",
    "joined_df['avg_sentence_length_ratio'] = joined_df['summary_avg_sentence_length'] / joined_df['prompt_text_avg_sentence_length']\n",
    "\n",
    "#percentage of unique words\n",
    "joined_df['prompt_text_unique_words_percentage'] = joined_df['prompt_text'].apply(get_unique_words_percentage)\n",
    "joined_df['summary_unique_words_percentage'] = joined_df['summary'].apply(get_unique_words_percentage)\n",
    "joined_df['unique_words_percentage_ratio'] = joined_df['summary_unique_words_percentage'] / joined_df['prompt_text_unique_words_percentage']\n",
    "\n",
    "#percentage of stopwords\n",
    "joined_df['prompt_text_stopwords_percentage'] = joined_df['prompt_text'].apply(get_stopwords_percentage)\n",
    "joined_df['summary_stopwords_percentage'] = joined_df['summary'].apply(get_stopwords_percentage)\n",
    "joined_df['stopwords_percentage_ratio'] = joined_df['summary_stopwords_percentage'] / joined_df['prompt_text_stopwords_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_ratio</th>\n",
       "      <th>prompt_text_avg_sentence_length</th>\n",
       "      <th>summary_avg_sentence_length</th>\n",
       "      <th>avg_sentence_length_ratio</th>\n",
       "      <th>prompt_text_unique_words_percentage</th>\n",
       "      <th>summary_unique_words_percentage</th>\n",
       "      <th>unique_words_percentage_ratio</th>\n",
       "      <th>prompt_text_stopwords_percentage</th>\n",
       "      <th>summary_stopwords_percentage</th>\n",
       "      <th>stopwords_percentage_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>The factories would use many different methods...</td>\n",
       "      <td>2.141224</td>\n",
       "      <td>1.123777</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[The, factories, would, use, many, different, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188199</td>\n",
       "      <td>42.73913</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0.432859</td>\n",
       "      <td>0.397762</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>1.426903</td>\n",
       "      <td>0.457782</td>\n",
       "      <td>0.535135</td>\n",
       "      <td>1.168973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>Meats that are not good get recycled, based on...</td>\n",
       "      <td>-1.216579</td>\n",
       "      <td>0.011840</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[Meats, that, are, not, good, get, recycled, ,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041709</td>\n",
       "      <td>42.73913</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.959308</td>\n",
       "      <td>0.397762</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>2.084836</td>\n",
       "      <td>0.457782</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>1.012304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>3 elements of an ideal tragedy described by Ar...</td>\n",
       "      <td>-0.157460</td>\n",
       "      <td>-0.165811</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[3, elements, of, an, ideal, tragedy, describe...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071192</td>\n",
       "      <td>24.16000</td>\n",
       "      <td>14.333333</td>\n",
       "      <td>0.593267</td>\n",
       "      <td>0.453642</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>1.640469</td>\n",
       "      <td>0.495033</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>1.127479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "5417  Summarize the various ways the factory would u...   \n",
       "6375  Summarize the various ways the factory would u...   \n",
       "562   Summarize at least 3 elements of an ideal trag...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "5417  Excerpt from The Jungle   \n",
       "6375  Excerpt from The Jungle   \n",
       "562                On Tragedy   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "5417  With one member trimming beef in a cannery, an...   \n",
       "6375  With one member trimming beef in a cannery, an...   \n",
       "562   Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "5417  The factories would use many different methods...  2.141224  1.123777   \n",
       "6375  Meats that are not good get recycled, based on... -1.216579  0.011840   \n",
       "562   3 elements of an ideal tragedy described by Ar... -0.157460 -0.165811   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "5417  [Summarize, the, various, ways, the, factory, ...   \n",
       "6375  [Summarize, the, various, ways, the, factory, ...   \n",
       "562   [Summarize, at, least, 3, elements, of, an, id...   \n",
       "\n",
       "            prompt_title_tokenized  \\\n",
       "5417  [Excerpt, from, The, Jungle]   \n",
       "6375  [Excerpt, from, The, Jungle]   \n",
       "562                  [On, Tragedy]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "5417  [With, one, member, trimming, beef, in, a, can...   \n",
       "6375  [With, one, member, trimming, beef, in, a, can...   \n",
       "562   [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "5417  [The, factories, would, use, many, different, ...  ...   \n",
       "6375  [Meats, that, are, not, good, get, recycled, ,...  ...   \n",
       "562   [3, elements, of, an, ideal, tragedy, describe...  ...   \n",
       "\n",
       "      word_count_ratio  prompt_text_avg_sentence_length  \\\n",
       "5417          0.188199                         42.73913   \n",
       "6375          0.041709                         42.73913   \n",
       "562           0.071192                         24.16000   \n",
       "\n",
       "      summary_avg_sentence_length  avg_sentence_length_ratio  \\\n",
       "5417                    18.500000                   0.432859   \n",
       "6375                    41.000000                   0.959308   \n",
       "562                     14.333333                   0.593267   \n",
       "\n",
       "      prompt_text_unique_words_percentage  summary_unique_words_percentage  \\\n",
       "5417                             0.397762                         0.567568   \n",
       "6375                             0.397762                         0.829268   \n",
       "562                              0.453642                         0.744186   \n",
       "\n",
       "      unique_words_percentage_ratio  prompt_text_stopwords_percentage  \\\n",
       "5417                       1.426903                          0.457782   \n",
       "6375                       2.084836                          0.457782   \n",
       "562                        1.640469                          0.495033   \n",
       "\n",
       "      summary_stopwords_percentage  stopwords_percentage_ratio  \n",
       "5417                      0.535135                    1.168973  \n",
       "6375                      0.463415                    1.012304  \n",
       "562                       0.558140                    1.127479  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_4'></a>\n",
    "### 3.4. Subjectivity and Polarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_question_non_stopwords</th>\n",
       "      <th>prompt_title_non_stopwords</th>\n",
       "      <th>prompt_text_non_stopwords</th>\n",
       "      <th>summary_non_stopwords</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>An ideal element for a tragedy is that the fal...</td>\n",
       "      <td>1.444398</td>\n",
       "      <td>1.889954</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[An, ideal, element, for, a, tragedy, is, that...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Summarize, least, 3, elements, ideal, tragedy...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, sequel, already, said, must,...</td>\n",
       "      <td>[An, ideal, element, tragedy, fall, antagonist...</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.274242</td>\n",
       "      <td>24.032493</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>1.353107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>The first element of a ideal tragedy should no...</td>\n",
       "      <td>-0.472653</td>\n",
       "      <td>-0.005224</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[The, first, element, of, a, ideal, tragedy, s...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Summarize, least, 3, elements, ideal, tragedy...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, sequel, already, said, must,...</td>\n",
       "      <td>[The, first, element, ideal, tragedy, simple, ...</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.034416</td>\n",
       "      <td>3.015917</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.404978</td>\n",
       "      <td>0.823841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>In the ancient times there where social classe...</td>\n",
       "      <td>-0.248808</td>\n",
       "      <td>0.383460</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[In, the, ancient, times, there, where, social...</td>\n",
       "      <td>...</td>\n",
       "      <td>[In, complete, sentences, summarize, structure...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, structured, like, pyramid,...</td>\n",
       "      <td>[In, ancient, times, social, classes, power, f...</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.336354</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.343056</td>\n",
       "      <td>0.694378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "173   Summarize at least 3 elements of an ideal trag...   \n",
       "692   Summarize at least 3 elements of an ideal trag...   \n",
       "3987  In complete sentences, summarize the structure...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "173                  On Tragedy   \n",
       "692                  On Tragedy   \n",
       "3987  Egyptian Social Structure   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "173   Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "692   Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "3987  Egyptian society was structured like a pyramid...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "173   An ideal element for a tragedy is that the fal...  1.444398  1.889954   \n",
       "692   The first element of a ideal tragedy should no... -0.472653 -0.005224   \n",
       "3987  In the ancient times there where social classe... -0.248808  0.383460   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "173   [Summarize, at, least, 3, elements, of, an, id...   \n",
       "692   [Summarize, at, least, 3, elements, of, an, id...   \n",
       "3987  [In, complete, sentences, ,, summarize, the, s...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "173                   [On, Tragedy]   \n",
       "692                   [On, Tragedy]   \n",
       "3987  [Egyptian, Social, Structure]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "173   [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "692   [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "3987  [Egyptian, society, was, structured, like, a, ...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "173   [An, ideal, element, for, a, tragedy, is, that...  ...   \n",
       "692   [The, first, element, of, a, ideal, tragedy, s...  ...   \n",
       "3987  [In, the, ancient, times, there, where, social...  ...   \n",
       "\n",
       "                          prompt_question_non_stopwords  \\\n",
       "173   [Summarize, least, 3, elements, ideal, tragedy...   \n",
       "692   [Summarize, least, 3, elements, ideal, tragedy...   \n",
       "3987  [In, complete, sentences, summarize, structure...   \n",
       "\n",
       "         prompt_title_non_stopwords  \\\n",
       "173                   [On, Tragedy]   \n",
       "692                   [On, Tragedy]   \n",
       "3987  [Egyptian, Social, Structure]   \n",
       "\n",
       "                              prompt_text_non_stopwords  \\\n",
       "173   [Chapter, 13, As, sequel, already, said, must,...   \n",
       "692   [Chapter, 13, As, sequel, already, said, must,...   \n",
       "3987  [Egyptian, society, structured, like, pyramid,...   \n",
       "\n",
       "                                  summary_non_stopwords  \\\n",
       "173   [An, ideal, element, tragedy, fall, antagonist...   \n",
       "692   [The, first, element, ideal, tragedy, simple, ...   \n",
       "3987  [In, ancient, times, social, classes, power, f...   \n",
       "\n",
       "      prompt_text_polarity_score  summary_polarity_score  \\\n",
       "173                     0.011411                0.274242   \n",
       "692                     0.011411                0.034416   \n",
       "3987                    0.206463                0.069444   \n",
       "\n",
       "      polarity_score_ratio  prompt_text_subjectivity_score  \\\n",
       "173              24.032493                        0.491573   \n",
       "692               3.015917                        0.491573   \n",
       "3987              0.336354                        0.494048   \n",
       "\n",
       "      summary_subjectivity_score  subjectivity_score_ratio  \n",
       "173                     0.665152                  1.353107  \n",
       "692                     0.404978                  0.823841  \n",
       "3987                    0.343056                  0.694378  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_text_polarity_score'] = joined_df['prompt_text'].apply(lambda x: polarity(x))\n",
    "joined_df['summary_polarity_score'] = joined_df['summary'].apply(lambda x: polarity(x))\n",
    "joined_df['polarity_score_ratio'] = joined_df['summary_polarity_score'] / joined_df['prompt_text_polarity_score']\n",
    "\n",
    "joined_df['prompt_text_subjectivity_score'] = joined_df['prompt_text'].apply(lambda x: subjectivity(x))\n",
    "joined_df['summary_subjectivity_score'] = joined_df['summary'].apply(lambda x: subjectivity(x))\n",
    "joined_df['subjectivity_score_ratio'] = joined_df['summary_subjectivity_score'] / joined_df['prompt_text_subjectivity_score']\n",
    "\n",
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_5'></a>\n",
    "### 3.5. Cosine similarity between prompt_text and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pre-trained SBERT model to perform prompt_text and summary embeddings. Then, we calculate cosine similarity between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284ae416826f41c6a575e1fb042c242e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85a5c916f2d4648b3cbfae1e33c4bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29f426fd3b2484f852fb3ed1b8c5dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd2d685b7074f479fac3e186554bc67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7858d3614d2b482296830750ba669340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bb8001fa/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830401b2514f45c88c2d658c66a0740f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fd0e3574824bd0b3bf6738e32cb432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e72d42e1c6fc4c70a0ad98f3bea4ed4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8f85de6362642c8bd4b89bb892bd79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d26dbb5f54f47fa9fb7f36776e051c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d900a4e3f2a1424dba2bff2d60d680ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed7f595aff8459c8af9620b9e55575e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4194a0ddec425f86f6502e4058f289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b8001fa/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "sbert_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(promp_text, summary):\n",
    "    \n",
    "    prompt_text_embedding = sbert_model.encode(promp_text, convert_to_tensor=True)\n",
    "    summary_embedding = sbert_model.encode(summary, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(summary_embedding, prompt_text_embedding)\n",
    "    \n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['cosine_similarity'] = joined_df.apply(lambda x: calculate_cosine_similarity(x['prompt_text'], x['summary']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_title_non_stopwords</th>\n",
       "      <th>prompt_text_non_stopwords</th>\n",
       "      <th>summary_non_stopwords</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>-0.382272</td>\n",
       "      <td>-1.795491</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, structured, like, pyramid,...</td>\n",
       "      <td>[Egyptian, society, structured, like, pyramid,...</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.908155</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.265060</td>\n",
       "      <td>0.654470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>Different social  classes were involved the go...</td>\n",
       "      <td>-0.393310</td>\n",
       "      <td>0.627128</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[Different, social, classes, were, involved, t...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, structured, like, pyramid,...</td>\n",
       "      <td>[Different, social, classes, involved, governm...</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>0.307222</td>\n",
       "      <td>1.488029</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.534444</td>\n",
       "      <td>1.081767</td>\n",
       "      <td>0.335529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>So every one was in this goverment giving the ...</td>\n",
       "      <td>-1.264214</td>\n",
       "      <td>-1.505073</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[So, every, one, was, in, this, goverment, giv...</td>\n",
       "      <td>...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, structured, like, pyramid,...</td>\n",
       "      <td>[So, every, one, goverment, giving, gods, sacr...</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>-0.350000</td>\n",
       "      <td>-1.695222</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.821687</td>\n",
       "      <td>0.417759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "2234  In complete sentences, summarize the structure...   \n",
       "3957  In complete sentences, summarize the structure...   \n",
       "2371  In complete sentences, summarize the structure...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "2234  Egyptian Social Structure   \n",
       "3957  Egyptian Social Structure   \n",
       "2371  Egyptian Social Structure   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "2234  Egyptian society was structured like a pyramid...   \n",
       "3957  Egyptian society was structured like a pyramid...   \n",
       "2371  Egyptian society was structured like a pyramid...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "2234  Egyptian society was structured like a pyramid... -0.382272 -1.795491   \n",
       "3957  Different social  classes were involved the go... -0.393310  0.627128   \n",
       "2371  So every one was in this goverment giving the ... -1.264214 -1.505073   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "2234  [In, complete, sentences, ,, summarize, the, s...   \n",
       "3957  [In, complete, sentences, ,, summarize, the, s...   \n",
       "2371  [In, complete, sentences, ,, summarize, the, s...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "2234  [Egyptian, Social, Structure]   \n",
       "3957  [Egyptian, Social, Structure]   \n",
       "2371  [Egyptian, Social, Structure]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "2234  [Egyptian, society, was, structured, like, a, ...   \n",
       "3957  [Egyptian, society, was, structured, like, a, ...   \n",
       "2371  [Egyptian, society, was, structured, like, a, ...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "2234  [Egyptian, society, was, structured, like, a, ...  ...   \n",
       "3957  [Different, social, classes, were, involved, t...  ...   \n",
       "2371  [So, every, one, was, in, this, goverment, giv...  ...   \n",
       "\n",
       "         prompt_title_non_stopwords  \\\n",
       "2234  [Egyptian, Social, Structure]   \n",
       "3957  [Egyptian, Social, Structure]   \n",
       "2371  [Egyptian, Social, Structure]   \n",
       "\n",
       "                              prompt_text_non_stopwords  \\\n",
       "2234  [Egyptian, society, structured, like, pyramid,...   \n",
       "3957  [Egyptian, society, structured, like, pyramid,...   \n",
       "2371  [Egyptian, society, structured, like, pyramid,...   \n",
       "\n",
       "                                  summary_non_stopwords  \\\n",
       "2234  [Egyptian, society, structured, like, pyramid,...   \n",
       "3957  [Different, social, classes, involved, governm...   \n",
       "2371  [So, every, one, goverment, giving, gods, sacr...   \n",
       "\n",
       "      prompt_text_polarity_score  summary_polarity_score  \\\n",
       "2234                    0.206463                0.187500   \n",
       "3957                    0.206463                0.307222   \n",
       "2371                    0.206463               -0.350000   \n",
       "\n",
       "      polarity_score_ratio  prompt_text_subjectivity_score  \\\n",
       "2234              0.908155                        0.494048   \n",
       "3957              1.488029                        0.494048   \n",
       "2371             -1.695222                        0.494048   \n",
       "\n",
       "      summary_subjectivity_score  subjectivity_score_ratio  cosine_similarity  \n",
       "2234                    0.625000                  1.265060           0.654470  \n",
       "3957                    0.534444                  1.081767           0.335529  \n",
       "2371                    0.900000                  1.821687           0.417759  \n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "joined_df['cosine_similarity'].hist(bins=50, grid=False)\n",
    "plt.title('Cosine Similarity Distribution')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_6'></a>\n",
    "### 3.6. Readability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>prompt_question_readability_score</th>\n",
       "      <th>summary_readability_score</th>\n",
       "      <th>readability_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>You must have a good plot not one that makes t...</td>\n",
       "      <td>0.376374</td>\n",
       "      <td>0.463619</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[You, must, have, a, good, plot, not, one, tha...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>0.388148</td>\n",
       "      <td>34.014313</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.467407</td>\n",
       "      <td>0.950839</td>\n",
       "      <td>0.507538</td>\n",
       "      <td>58.28</td>\n",
       "      <td>70.77</td>\n",
       "      <td>1.214310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4204</th>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The Third Wave developed quickly over a short ...</td>\n",
       "      <td>1.044649</td>\n",
       "      <td>0.958534</td>\n",
       "      <td>[Summarize, how, the, Third, Wave, developed, ...</td>\n",
       "      <td>[The, Third, Wave]</td>\n",
       "      <td>[Background, The, Third, Wave, experiment, too...</td>\n",
       "      <td>[The, Third, Wave, developed, quickly, over, a...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004218</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>-8.115043</td>\n",
       "      <td>0.359906</td>\n",
       "      <td>0.348115</td>\n",
       "      <td>0.967238</td>\n",
       "      <td>0.560570</td>\n",
       "      <td>60.65</td>\n",
       "      <td>68.50</td>\n",
       "      <td>1.129431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>At the top of social class were the gods that ...</td>\n",
       "      <td>-0.093814</td>\n",
       "      <td>0.503833</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[At, the, top, of, social, class, were, the, g...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.291598</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.573494</td>\n",
       "      <td>0.450743</td>\n",
       "      <td>53.88</td>\n",
       "      <td>87.92</td>\n",
       "      <td>1.631774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "1918  Summarize at least 3 elements of an ideal trag...   \n",
       "4204  Summarize how the Third Wave developed over su...   \n",
       "3443  In complete sentences, summarize the structure...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "1918                 On Tragedy   \n",
       "4204             The Third Wave   \n",
       "3443  Egyptian Social Structure   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "1918  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "4204  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3443  Egyptian society was structured like a pyramid...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "1918  You must have a good plot not one that makes t...  0.376374  0.463619   \n",
       "4204  The Third Wave developed quickly over a short ...  1.044649  0.958534   \n",
       "3443  At the top of social class were the gods that ... -0.093814  0.503833   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "1918  [Summarize, at, least, 3, elements, of, an, id...   \n",
       "4204  [Summarize, how, the, Third, Wave, developed, ...   \n",
       "3443  [In, complete, sentences, ,, summarize, the, s...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "1918                  [On, Tragedy]   \n",
       "4204             [The, Third, Wave]   \n",
       "3443  [Egyptian, Social, Structure]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "1918  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "4204  [Background, The, Third, Wave, experiment, too...   \n",
       "3443  [Egyptian, society, was, structured, like, a, ...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "1918  [You, must, have, a, good, plot, not, one, tha...  ...   \n",
       "4204  [The, Third, Wave, developed, quickly, over, a...  ...   \n",
       "3443  [At, the, top, of, social, class, were, the, g...  ...   \n",
       "\n",
       "      prompt_text_polarity_score  summary_polarity_score  \\\n",
       "1918                    0.011411                0.388148   \n",
       "4204                   -0.004218                0.034226   \n",
       "3443                    0.206463                0.266667   \n",
       "\n",
       "      polarity_score_ratio  prompt_text_subjectivity_score  \\\n",
       "1918             34.014313                        0.491573   \n",
       "4204             -8.115043                        0.359906   \n",
       "3443              1.291598                        0.494048   \n",
       "\n",
       "      summary_subjectivity_score  subjectivity_score_ratio  cosine_similarity  \\\n",
       "1918                    0.467407                  0.950839           0.507538   \n",
       "4204                    0.348115                  0.967238           0.560570   \n",
       "3443                    0.283333                  0.573494           0.450743   \n",
       "\n",
       "      prompt_question_readability_score  summary_readability_score  \\\n",
       "1918                              58.28                      70.77   \n",
       "4204                              60.65                      68.50   \n",
       "3443                              53.88                      87.92   \n",
       "\n",
       "      readability_score_ratio  \n",
       "1918                 1.214310  \n",
       "4204                 1.129431  \n",
       "3443                 1.631774  \n",
       "\n",
       "[3 rows x 39 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_question_readability_score'] = joined_df['prompt_question'].apply(lambda x: flesch_reading_ease(x))\n",
    "joined_df['summary_readability_score'] = joined_df['summary'].apply(lambda x: flesch_reading_ease(x))\n",
    "joined_df['readability_score_ratio'] = joined_df['summary_readability_score'] / joined_df['prompt_question_readability_score']\n",
    "\n",
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_7'></a>\n",
    "### 3.7. Misspelling frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "sc = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_misspeling_percentage(word_list):\n",
    "\n",
    "    misspelled = sc.unknown(word_list)\n",
    "    percentage_of_misspelled = len(misspelled)/len(word_list)\n",
    "    \n",
    "    return percentage_of_misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['summary_misspelled_words_percentage'] = joined_df['summary_tokenized'].apply(lambda x: calculate_misspeling_percentage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>prompt_question_readability_score</th>\n",
       "      <th>summary_readability_score</th>\n",
       "      <th>readability_score_ratio</th>\n",
       "      <th>summary_misspelled_words_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3226</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>The different social classes had their duties....</td>\n",
       "      <td>0.798306</td>\n",
       "      <td>1.387432</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[The, different, social, classes, had, their, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0.297673</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.944578</td>\n",
       "      <td>0.425381</td>\n",
       "      <td>53.88</td>\n",
       "      <td>66.33</td>\n",
       "      <td>1.231069</td>\n",
       "      <td>0.028571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>in the text they have a goverment structure an...</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>-1.256748</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[in, the, text, they, have, a, goverment, stru...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.726524</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.012048</td>\n",
       "      <td>0.799393</td>\n",
       "      <td>53.88</td>\n",
       "      <td>75.20</td>\n",
       "      <td>1.395694</td>\n",
       "      <td>0.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4769</th>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>After only three days, the experiment took on ...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "      <td>[Summarize, how, the, Third, Wave, developed, ...</td>\n",
       "      <td>[The, Third, Wave]</td>\n",
       "      <td>[Background, The, Third, Wave, experiment, too...</td>\n",
       "      <td>[After, only, three, days, ,, the, experiment,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>-47.420079</td>\n",
       "      <td>0.359906</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.852334</td>\n",
       "      <td>0.420729</td>\n",
       "      <td>60.65</td>\n",
       "      <td>72.16</td>\n",
       "      <td>1.189777</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "3226  In complete sentences, summarize the structure...   \n",
       "3916  In complete sentences, summarize the structure...   \n",
       "4769  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "3226  Egyptian Social Structure   \n",
       "3916  Egyptian Social Structure   \n",
       "4769             The Third Wave   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "3226  Egyptian society was structured like a pyramid...   \n",
       "3916  Egyptian society was structured like a pyramid...   \n",
       "4769  Background \\r\\nThe Third Wave experiment took ...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "3226  The different social classes had their duties....  0.798306  1.387432   \n",
       "3916  in the text they have a goverment structure an...  0.003053 -1.256748   \n",
       "4769  After only three days, the experiment took on ... -1.547163 -1.461245   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "3226  [In, complete, sentences, ,, summarize, the, s...   \n",
       "3916  [In, complete, sentences, ,, summarize, the, s...   \n",
       "4769  [Summarize, how, the, Third, Wave, developed, ...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "3226  [Egyptian, Social, Structure]   \n",
       "3916  [Egyptian, Social, Structure]   \n",
       "4769             [The, Third, Wave]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "3226  [Egyptian, society, was, structured, like, a, ...   \n",
       "3916  [Egyptian, society, was, structured, like, a, ...   \n",
       "4769  [Background, The, Third, Wave, experiment, too...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "3226  [The, different, social, classes, had, their, ...  ...   \n",
       "3916  [in, the, text, they, have, a, goverment, stru...  ...   \n",
       "4769  [After, only, three, days, ,, the, experiment,...  ...   \n",
       "\n",
       "      summary_polarity_score  polarity_score_ratio  \\\n",
       "3226                0.061458              0.297673   \n",
       "3916                0.150000              0.726524   \n",
       "4769                0.200000            -47.420079   \n",
       "\n",
       "      prompt_text_subjectivity_score  summary_subjectivity_score  \\\n",
       "3226                        0.494048                    0.466667   \n",
       "3916                        0.494048                    0.500000   \n",
       "4769                        0.359906                    0.666667   \n",
       "\n",
       "      subjectivity_score_ratio  cosine_similarity  \\\n",
       "3226                  0.944578           0.425381   \n",
       "3916                  1.012048           0.799393   \n",
       "4769                  1.852334           0.420729   \n",
       "\n",
       "      prompt_question_readability_score  summary_readability_score  \\\n",
       "3226                              53.88                      66.33   \n",
       "3916                              53.88                      75.20   \n",
       "4769                              60.65                      72.16   \n",
       "\n",
       "      readability_score_ratio  summary_misspelled_words_percentage  \n",
       "3226                 1.231069                             0.028571  \n",
       "3916                 1.395694                             0.027397  \n",
       "4769                 1.189777                             0.000000  \n",
       "\n",
       "[3 rows x 40 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_8'></a>\n",
    "### 3.8. Topic overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_8_1'></a>\n",
    "#### 3.8.1 Stopword filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop and word.isalnum()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['prompt_question_non_stopwords'] = joined_df['prompt_question_tokenized'].apply(filter_stopwords)\n",
    "joined_df['prompt_title_non_stopwords'] = joined_df['prompt_title_tokenized'].apply(filter_stopwords)\n",
    "joined_df['prompt_text_non_stopwords'] = joined_df['prompt_text_tokenized'].apply(filter_stopwords)\n",
    "joined_df['summary_non_stopwords'] = joined_df['summary_tokenized'].apply(filter_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_8_2'></a>\n",
    "#### 3.8.2 Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_overlap(prompt_question, prompt_text, summary):\n",
    "    \n",
    "    num_topics = 3\n",
    "    num_passes = 15\n",
    "    num_words = 5\n",
    "    \n",
    "    #tokenize\n",
    "    prompt_question_tokens = prompt_question.apply(lambda x: word_tokenize(x))\n",
    "    prompt_text_tokens = prompt_text.apply(lambda x: word_tokenize(x))\n",
    "    prompt_summary_tokens = summary.apply(lambda x: word_tokenize(x))\n",
    "    \n",
    "    #remove stopwords\n",
    "    prompt_question_non_stopwords = prompt_question_tokens.apply(filter_stopwords)\n",
    "    prompt_text_non_stopwords = prompt_text_tokens.apply(filter_stopwords)\n",
    "    prompt_summary_non_stopwords = prompt_summary_tokens.apply(filter_stopwords)\n",
    "    \n",
    "    #remove special characters\n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    \n",
    "    prompt_question_non_stopwords = prompt_question_non_stopwords.apply(lambda x: [word for word in x if word not in special_characters])\n",
    "    prompt_text_non_stopwords = prompt_text_non_stopwords.apply(lambda x: [word for word in x if word not in special_characters])\n",
    "    prompt_summary_non_stopwords = prompt_summary_non_stopwords.apply(lambda x: [word for word in x if word not in special_characters])    \n",
    "    \n",
    "    #lowercase\n",
    "    prompt_question_non_stopwords = prompt_question_non_stopwords.apply(lambda x: [word.lower() for word in x])\n",
    "    prompt_text_non_stopwords = prompt_text_non_stopwords.apply(lambda x: [word.lower() for word in x])\n",
    "    prompt_summary_non_stopwords = prompt_summary_non_stopwords.apply(lambda x: [word.lower() for word in x])\n",
    "    \n",
    "    #flatten lists to create corpus\n",
    "    prompt_combined = prompt_question_non_stopwords + prompt_text_non_stopwords\n",
    "    corpus_prompt = [word for sublist in prompt_combined for word in sublist]\n",
    "    corpus_summary = [word for sublist in prompt_summary_non_stopwords for word in sublist]\n",
    "    \n",
    "    #lemmatize and wrap in list for gensim (i.e. create list of lists as gensim expects)\n",
    "    infinitives_prompt = [[lem.lemmatize(w) for w in corpus_prompt if len(w)>3]] # lemmatizing only words longer than 3 characters\n",
    "    infinitives_summary = [[lem.lemmatize(w) for w in corpus_summary if len(w)>3]] # lemmatizing only words longer than 3 characters\n",
    "    \n",
    "    #create dictionary\n",
    "    dictionary_prompt = corpora.Dictionary(infinitives_prompt)\n",
    "    dictionary_summary = corpora.Dictionary(infinitives_summary)\n",
    "    \n",
    "    #create bag of words corpus\n",
    "    bow_corpus_prompt = [dictionary_prompt.doc2bow(doc) for doc in infinitives_prompt]\n",
    "    bow_corpus_summary = [dictionary_summary.doc2bow(doc) for doc in infinitives_summary]\n",
    "    \n",
    "    #create LDA model\n",
    "    lda_model_prompt = LdaModel(bow_corpus_prompt, num_topics=num_topics, id2word=dictionary_prompt, passes=num_passes)\n",
    "    lda_model_summary = LdaModel(bow_corpus_summary, num_topics=num_topics, id2word=dictionary_summary, passes=15)\n",
    "    \n",
    "    #get topics\n",
    "    topics_prompt = lda_model_prompt.print_topics(num_words=num_words)\n",
    "    topic_summary = lda_model_summary.print_topics(num_words=num_words)\n",
    "    \n",
    "    #get words describing topics and calculate cosine similarity between them\n",
    "    topics_prompt_words = \" \".join([\" \".join(re.findall(r'\"([^\"]*)\"', topic[1])) for topic in topics_prompt])\n",
    "    topics_summary_words = \" \".join([\" \".join(re.findall(r'\"([^\"]*)\"', topic[1])) for topic in topic_summary])\n",
    "    \n",
    "    topic_overlap = calculate_cosine_similarity(topics_prompt_words, topics_summary_words)\n",
    "        \n",
    "    return topics_prompt_words, topics_summary_words, topic_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_df['topics_prompt_words'], joined_df['topics_summary_words'], joined_df['topic_overlap'] = zip(*calculate_topic_overlap(joined_df['prompt_question'], joined_df['prompt_text'], joined_df['summary']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CommonLit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
