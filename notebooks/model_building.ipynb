{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "# Table of contents\n",
    "\n",
    "#### 1. [Package instalation (optional)](#1)\n",
    "#### 2. [Data loading](#2)\n",
    "#### 3. [Feature Engineering](#3)\n",
    "- ##### 3.1. [Outline](#3_1)\n",
    "- ##### 3.2. [Tokenization](#3_2)\n",
    "- ##### 3.3. [Basic word- and sentence-level metrics](#3_3)\n",
    "- ##### 3.4. [Subjectivity and Polarity metrics](#3_4)\n",
    "- ##### 3.5. [Cosine subjectivity between prompt_text and summary](#3_5)\n",
    "- ##### 3.6. [Readability score](#3_6)\n",
    "- ##### 3.7. [Misspelling frequency](#3_7)\n",
    "- ##### 3.8. [Topic overlap](#3_8)\n",
    "- ##### 3.9. [N-gram overlap](#3_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting word2number\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: word2number\n",
      "  Building wheel for word2number (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5567 sha256=bbeedc7e38d74e78777c338aac8b0f400ff4146c4f6a1b37993206af5547b5c8\n",
      "  Stored in directory: /Users/duje/Library/Caches/pip/wheels/cd/ef/ae/073b491b14d25e2efafcffca9e16b2ee6d114ec5c643ba4f06\n",
      "Successfully built word2number\n",
      "Installing collected packages: word2number\n",
      "Successfully installed word2number-1.1\n"
     ]
    }
   ],
   "source": [
    "#! pip install transformers sentence-transformers\n",
    "! pip install word2number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries_train_df = pd.read_csv('../data/summaries_train.csv')\n",
    "prompts_train_df = pd.read_csv('../data/prompts_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prompt_question prompt_title  \\\n",
       "0  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                             summary   content   wording  \n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415  \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058  \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join the two data frames based on a unique key and drop unnecessary columns\n",
    "joined_df = pd.merge(prompts_train_df, summaries_train_df, on = 'prompt_id')\n",
    "joined_df.drop(['prompt_id', 'student_id'], axis = 1, inplace = True)\n",
    "\n",
    "#rename 'text' column to 'summary'\n",
    "joined_df.rename(columns = {'text' : 'summary'}, inplace=True)\n",
    "\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_1'></a>\n",
    "### 3.1. Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final goal is to train the model to predict content and wording scores.\n",
    "\n",
    "• Wording Model  \n",
    "\n",
    "a) Voice\n",
    "\n",
    "Voice in writing refers to the author's distinctive style and tone. In the context of grading student summaries, \"using objective language\" means that the summary should avoid personal opinions, emotional language, or subjective statements. It should be neutral and objective, presenting the facts from the source text without adding the author's own perspective.  \n",
    "\n",
    "b) Paraphrase  \n",
    "\n",
    "Paraphrasing involves restating the information from the source text in a new way, without changing its meaning. A high score in paraphrasing means that the summary effectively conveys the key points of the source text in a concise and clear manner. It should avoid direct copying of sentences from the source.\n",
    "\n",
    "c) Language  \n",
    "\n",
    "This component assesses the quality of the language used in the summary. It considers factors such as vocabulary choice, sentence structure, and grammar. A good summary should use appropriate and varied vocabulary, follow correct grammar rules, and have coherent sentence structure.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• Content Scores: \n",
    "\n",
    "a) Main idea  \n",
    "\n",
    "This aspect evaluates how well the summary captures the primary message or main idea of the source text. A high score means that the summary effectively identifies and conveys the central theme or argument of the source.  \n",
    "\n",
    "b) Details  \n",
    "\n",
    "Details refer to specific information, examples, or evidence from the source text. A good summary should accurately represent these details without omitting crucial information or including irrelevant details. The summary should focus on the most relevant supporting details.  \n",
    "\n",
    "c) Cohesion  \n",
    "\n",
    "Cohesion assesses how well the summary transitions from one idea to the next. It considers the flow of the summary and how well sentences and paragraphs are connected. A high score indicates that the summary has a logical and smooth progression of ideas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some features that could be useful:  \n",
    "\n",
    "• Extract average sentence length, average word length, word count, unique and stopwords percentage from prompt_text and summary and divide to create new feature.  \n",
    "\n",
    "• For each summary calculate subjectivity and emotional tone (polarity).  \n",
    "\n",
    "• Calculate cosine similarity between prompt_text and summary.  \n",
    "\n",
    "• Calculate readability score. \n",
    "\n",
    "• Calculate frequency of misspelled words in student summaries.   \n",
    "\n",
    "• Extract topics from prompt_text, prompt_question and student summaries. Use overlap as a feature.  \n",
    "\n",
    "• Calculate most used 2-grams and 3-grams in prompt_text and summaries and calculate overlap in the 2 categories. Use this as a new feature. \n",
    "\n",
    "• Perform Named Entity Recognition (NER) on prompt_text and summaries, and calculate overlap to access if relevant features are captured.  \n",
    "\n",
    "• Calculate the frequency of transition words in summaries to evaluate cohesion.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_2'></a>\n",
    "### 3.2. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download the 'punkt' resource\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[1, element, of, an, ideal, tragedy, is, that,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[The, three, elements, of, an, ideal, tragedy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>Aristotle states that an ideal tragedy should ...</td>\n",
       "      <td>-0.387791</td>\n",
       "      <td>-0.584181</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[Aristotle, states, that, an, ideal, tragedy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     prompt_question prompt_title  \\\n",
       "0  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "1  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "2  Summarize at least 3 elements of an ideal trag...   On Tragedy   \n",
       "\n",
       "                                         prompt_text  \\\n",
       "0  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "1  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "2  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                             summary   content   wording  \\\n",
       "0  1 element of an ideal tragedy is that it shoul... -0.210614 -0.471415   \n",
       "1  The three elements of an ideal tragedy are:  H... -0.970237 -0.417058   \n",
       "2  Aristotle states that an ideal tragedy should ... -0.387791 -0.584181   \n",
       "\n",
       "                           prompt_question_tokenized prompt_title_tokenized  \\\n",
       "0  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "1  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "2  [Summarize, at, least, 3, elements, of, an, id...          [On, Tragedy]   \n",
       "\n",
       "                               prompt_text_tokenized  \\\n",
       "0  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "1  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "2  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "\n",
       "                                   summary_tokenized  \n",
       "0  [1, element, of, an, ideal, tragedy, is, that,...  \n",
       "1  [The, three, elements, of, an, ideal, tragedy,...  \n",
       "2  [Aristotle, states, that, an, ideal, tragedy, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_question_tokenized'] = joined_df['prompt_question'].apply(word_tokenize)\n",
    "joined_df['prompt_title_tokenized'] = joined_df['prompt_title'].apply(word_tokenize)\n",
    "joined_df['prompt_text_tokenized'] = joined_df['prompt_text'].apply(word_tokenize)\n",
    "joined_df['summary_tokenized'] = joined_df['summary'].apply(word_tokenize)\n",
    "\n",
    "joined_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_3'></a>\n",
    "### 3.3. Basic word- and sentence-level metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sentences(text):\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    sentence_count = len(sentences)\n",
    "    \n",
    "    return sentence_count\n",
    "\n",
    "def count_total_words(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    word_count = len(words)\n",
    "    \n",
    "    return word_count\n",
    "\n",
    "def get_unique_words_percentage(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    unique_words = set(words)\n",
    "    unique_word_count = len(unique_words)\n",
    "    \n",
    "    unique_word_percentage = unique_word_count / len(words)\n",
    "    \n",
    "    return unique_word_percentage    \n",
    "    \n",
    "def get_stopwords_percentage(text):\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    stopwords = [word for word in words if word not in stop and word.isalnum()]\n",
    "\n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    words = [word for word in words if word not in special_characters]\n",
    "    \n",
    "    stopwords_percentage = len(stopwords) / len(words)\n",
    "    \n",
    "    return stopwords_percentage\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentence count\n",
    "joined_df['prompt_text_sentence_count'] = joined_df['prompt_text'].apply(count_sentences)\n",
    "joined_df['summary_sentence_count'] = joined_df['summary'].apply(count_sentences)\n",
    "joined_df['sentence_count_ratio'] = joined_df['summary_sentence_count'] / joined_df['prompt_text_sentence_count']\n",
    "\n",
    "#word count\n",
    "joined_df['prompt_text_word_count'] = joined_df['prompt_text'].apply(count_total_words)\n",
    "joined_df['summary_word_count'] = joined_df['summary'].apply(count_total_words)\n",
    "joined_df['word_count_ratio'] = joined_df['summary_word_count'] / joined_df['prompt_text_word_count']\n",
    "\n",
    "#average sentence length\n",
    "joined_df['prompt_text_avg_sentence_length'] = joined_df['prompt_text_word_count'] / joined_df['prompt_text_sentence_count']\n",
    "joined_df['summary_avg_sentence_length'] = joined_df['summary_word_count'] / joined_df['summary_sentence_count']\n",
    "joined_df['avg_sentence_length_ratio'] = joined_df['summary_avg_sentence_length'] / joined_df['prompt_text_avg_sentence_length']\n",
    "\n",
    "#percentage of unique words\n",
    "joined_df['prompt_text_unique_words_percentage'] = joined_df['prompt_text'].apply(get_unique_words_percentage)\n",
    "joined_df['summary_unique_words_percentage'] = joined_df['summary'].apply(get_unique_words_percentage)\n",
    "joined_df['unique_words_percentage_ratio'] = joined_df['summary_unique_words_percentage'] / joined_df['prompt_text_unique_words_percentage']\n",
    "\n",
    "#percentage of stopwords\n",
    "joined_df['prompt_text_stopwords_percentage'] = joined_df['prompt_text'].apply(get_stopwords_percentage)\n",
    "joined_df['summary_stopwords_percentage'] = joined_df['summary'].apply(get_stopwords_percentage)\n",
    "joined_df['stopwords_percentage_ratio'] = joined_df['summary_stopwords_percentage'] / joined_df['prompt_text_stopwords_percentage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>word_count_ratio</th>\n",
       "      <th>prompt_text_avg_sentence_length</th>\n",
       "      <th>summary_avg_sentence_length</th>\n",
       "      <th>avg_sentence_length_ratio</th>\n",
       "      <th>prompt_text_unique_words_percentage</th>\n",
       "      <th>summary_unique_words_percentage</th>\n",
       "      <th>unique_words_percentage_ratio</th>\n",
       "      <th>prompt_text_stopwords_percentage</th>\n",
       "      <th>summary_stopwords_percentage</th>\n",
       "      <th>stopwords_percentage_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>It developed because everyone wanted to fit in...</td>\n",
       "      <td>-0.667585</td>\n",
       "      <td>-0.163822</td>\n",
       "      <td>[Summarize, how, the, Third, Wave, developed, ...</td>\n",
       "      <td>[The, Third, Wave]</td>\n",
       "      <td>[Background, The, Third, Wave, experiment, too...</td>\n",
       "      <td>[It, developed, because, everyone, wanted, to,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>24.360000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.466338</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>2.070423</td>\n",
       "      <td>0.525452</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.853125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>The structure of the ancient egyptcians was li...</td>\n",
       "      <td>0.142037</td>\n",
       "      <td>-0.289107</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[The, structure, of, the, ancient, egyptcians,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144144</td>\n",
       "      <td>12.613636</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>2.114114</td>\n",
       "      <td>0.549550</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>1.410246</td>\n",
       "      <td>0.601802</td>\n",
       "      <td>0.537500</td>\n",
       "      <td>0.893151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>The Third Wave quickly picked up speed and gre...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>[Summarize, how, the, Third, Wave, developed, ...</td>\n",
       "      <td>[The, Third, Wave]</td>\n",
       "      <td>[Background, The, Third, Wave, experiment, too...</td>\n",
       "      <td>[The, Third, Wave, quickly, picked, up, speed,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110016</td>\n",
       "      <td>24.360000</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>0.550082</td>\n",
       "      <td>0.466338</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>1.792306</td>\n",
       "      <td>0.525452</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>1.107789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "4885  Summarize how the Third Wave developed over su...   \n",
       "3826  In complete sentences, summarize the structure...   \n",
       "5042  Summarize how the Third Wave developed over su...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "4885             The Third Wave   \n",
       "3826  Egyptian Social Structure   \n",
       "5042             The Third Wave   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "4885  Background \\r\\nThe Third Wave experiment took ...   \n",
       "3826  Egyptian society was structured like a pyramid...   \n",
       "5042  Background \\r\\nThe Third Wave experiment took ...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "4885  It developed because everyone wanted to fit in... -0.667585 -0.163822   \n",
       "3826  The structure of the ancient egyptcians was li...  0.142037 -0.289107   \n",
       "5042  The Third Wave quickly picked up speed and gre...  0.205683  0.380538   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "4885  [Summarize, how, the, Third, Wave, developed, ...   \n",
       "3826  [In, complete, sentences, ,, summarize, the, s...   \n",
       "5042  [Summarize, how, the, Third, Wave, developed, ...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "4885             [The, Third, Wave]   \n",
       "3826  [Egyptian, Social, Structure]   \n",
       "5042             [The, Third, Wave]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "4885  [Background, The, Third, Wave, experiment, too...   \n",
       "3826  [Egyptian, society, was, structured, like, a, ...   \n",
       "5042  [Background, The, Third, Wave, experiment, too...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "4885  [It, developed, because, everyone, wanted, to,...  ...   \n",
       "3826  [The, structure, of, the, ancient, egyptcians,...  ...   \n",
       "5042  [The, Third, Wave, quickly, picked, up, speed,...  ...   \n",
       "\n",
       "      word_count_ratio  prompt_text_avg_sentence_length  \\\n",
       "4885          0.047619                        24.360000   \n",
       "3826          0.144144                        12.613636   \n",
       "5042          0.110016                        24.360000   \n",
       "\n",
       "      summary_avg_sentence_length  avg_sentence_length_ratio  \\\n",
       "4885                    14.500000                   0.595238   \n",
       "3826                    26.666667                   2.114114   \n",
       "5042                    13.400000                   0.550082   \n",
       "\n",
       "      prompt_text_unique_words_percentage  summary_unique_words_percentage  \\\n",
       "4885                             0.466338                         0.965517   \n",
       "3826                             0.549550                         0.775000   \n",
       "5042                             0.466338                         0.835821   \n",
       "\n",
       "      unique_words_percentage_ratio  prompt_text_stopwords_percentage  \\\n",
       "4885                       2.070423                          0.525452   \n",
       "3826                       1.410246                          0.601802   \n",
       "5042                       1.792306                          0.525452   \n",
       "\n",
       "      summary_stopwords_percentage  stopwords_percentage_ratio  \n",
       "4885                      0.448276                    0.853125  \n",
       "3826                      0.537500                    0.893151  \n",
       "5042                      0.582090                    1.107789  \n",
       "\n",
       "[3 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_4'></a>\n",
    "### 3.4. Subjectivity and Polarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def polarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "def subjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>unique_words_percentage_ratio</th>\n",
       "      <th>prompt_text_stopwords_percentage</th>\n",
       "      <th>summary_stopwords_percentage</th>\n",
       "      <th>stopwords_percentage_ratio</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2544</th>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>The government of ancient Egypt worked as a hi...</td>\n",
       "      <td>0.531368</td>\n",
       "      <td>0.583991</td>\n",
       "      <td>[In, complete, sentences, ,, summarize, the, s...</td>\n",
       "      <td>[Egyptian, Social, Structure]</td>\n",
       "      <td>[Egyptian, society, was, structured, like, a, ...</td>\n",
       "      <td>[The, government, of, ancient, Egypt, worked, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.206300</td>\n",
       "      <td>0.601802</td>\n",
       "      <td>0.617978</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>0.206463</td>\n",
       "      <td>1.170068e-01</td>\n",
       "      <td>5.667216e-01</td>\n",
       "      <td>0.494048</td>\n",
       "      <td>0.671769</td>\n",
       "      <td>1.359725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6590</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>Factories used various to cover up spoiled mea...</td>\n",
       "      <td>-0.002466</td>\n",
       "      <td>-0.045439</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[Factories, used, various, to, cover, up, spoi...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.850632</td>\n",
       "      <td>0.457782</td>\n",
       "      <td>0.569444</td>\n",
       "      <td>1.243920</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>-1.000000e-01</td>\n",
       "      <td>4.222277e+01</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.535557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6188</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>the meat packaging industry used many ways to ...</td>\n",
       "      <td>-0.301962</td>\n",
       "      <td>0.077857</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[the, meat, packaging, industry, used, many, w...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.637952</td>\n",
       "      <td>0.457782</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>1.026027</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>5.551115e-17</td>\n",
       "      <td>-2.343834e-14</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>1.208437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "2544  In complete sentences, summarize the structure...   \n",
       "6590  Summarize the various ways the factory would u...   \n",
       "6188  Summarize the various ways the factory would u...   \n",
       "\n",
       "                   prompt_title  \\\n",
       "2544  Egyptian Social Structure   \n",
       "6590    Excerpt from The Jungle   \n",
       "6188    Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "2544  Egyptian society was structured like a pyramid...   \n",
       "6590  With one member trimming beef in a cannery, an...   \n",
       "6188  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "2544  The government of ancient Egypt worked as a hi...  0.531368  0.583991   \n",
       "6590  Factories used various to cover up spoiled mea... -0.002466 -0.045439   \n",
       "6188  the meat packaging industry used many ways to ... -0.301962  0.077857   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "2544  [In, complete, sentences, ,, summarize, the, s...   \n",
       "6590  [Summarize, the, various, ways, the, factory, ...   \n",
       "6188  [Summarize, the, various, ways, the, factory, ...   \n",
       "\n",
       "             prompt_title_tokenized  \\\n",
       "2544  [Egyptian, Social, Structure]   \n",
       "6590   [Excerpt, from, The, Jungle]   \n",
       "6188   [Excerpt, from, The, Jungle]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "2544  [Egyptian, society, was, structured, like, a, ...   \n",
       "6590  [With, one, member, trimming, beef, in, a, can...   \n",
       "6188  [With, one, member, trimming, beef, in, a, can...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "2544  [The, government, of, ancient, Egypt, worked, ...  ...   \n",
       "6590  [Factories, used, various, to, cover, up, spoi...  ...   \n",
       "6188  [the, meat, packaging, industry, used, many, w...  ...   \n",
       "\n",
       "      unique_words_percentage_ratio  prompt_text_stopwords_percentage  \\\n",
       "2544                       1.206300                          0.601802   \n",
       "6590                       1.850632                          0.457782   \n",
       "6188                       1.637952                          0.457782   \n",
       "\n",
       "      summary_stopwords_percentage  stopwords_percentage_ratio  \\\n",
       "2544                      0.617978                    1.026879   \n",
       "6590                      0.569444                    1.243920   \n",
       "6188                      0.469697                    1.026027   \n",
       "\n",
       "      prompt_text_polarity_score  summary_polarity_score  \\\n",
       "2544                    0.206463            1.170068e-01   \n",
       "6590                   -0.002368           -1.000000e-01   \n",
       "6188                   -0.002368            5.551115e-17   \n",
       "\n",
       "      polarity_score_ratio  prompt_text_subjectivity_score  \\\n",
       "2544          5.667216e-01                        0.494048   \n",
       "6590          4.222277e+01                        0.404563   \n",
       "6188         -2.343834e-14                        0.404563   \n",
       "\n",
       "      summary_subjectivity_score  subjectivity_score_ratio  \n",
       "2544                    0.671769                  1.359725  \n",
       "6590                    0.216667                  0.535557  \n",
       "6188                    0.488889                  1.208437  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_text_polarity_score'] = joined_df['prompt_text'].apply(lambda x: polarity(x))\n",
    "joined_df['summary_polarity_score'] = joined_df['summary'].apply(lambda x: polarity(x))\n",
    "joined_df['polarity_score_ratio'] = joined_df['summary_polarity_score'] / joined_df['prompt_text_polarity_score']\n",
    "\n",
    "joined_df['prompt_text_subjectivity_score'] = joined_df['prompt_text'].apply(lambda x: subjectivity(x))\n",
    "joined_df['summary_subjectivity_score'] = joined_df['summary'].apply(lambda x: subjectivity(x))\n",
    "joined_df['subjectivity_score_ratio'] = joined_df['summary_subjectivity_score'] / joined_df['prompt_text_subjectivity_score']\n",
    "\n",
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_5'></a>\n",
    "### 3.5. Cosine similarity between prompt_text and summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pre-trained SBERT model to perform prompt_text and summary embeddings. Then, we calculate cosine similarity between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "sbert_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(promp_text, summary):\n",
    "    \n",
    "    prompt_text_embedding = sbert_model.encode(promp_text, convert_to_tensor=True)\n",
    "    summary_embedding = sbert_model.encode(summary, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(summary_embedding, prompt_text_embedding)\n",
    "    \n",
    "    return similarity.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['cosine_similarity'] = joined_df.apply(lambda x: calculate_cosine_similarity(x['prompt_text'], x['summary']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cosine_similarity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cosine_similarity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/duje/Documents/Data_science/kaggle/projects/CommonLit/notebooks/model_building.ipynb Cell 35\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/duje/Documents/Data_science/kaggle/projects/CommonLit/notebooks/model_building.ipynb#X64sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/duje/Documents/Data_science/kaggle/projects/CommonLit/notebooks/model_building.ipynb#X64sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m joined_df[\u001b[39m'\u001b[39;49m\u001b[39mcosine_similarity\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mhist(bins\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, grid\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/duje/Documents/Data_science/kaggle/projects/CommonLit/notebooks/model_building.ipynb#X64sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mCosine Similarity Distribution\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/duje/Documents/Data_science/kaggle/projects/CommonLit/notebooks/model_building.ipynb#X64sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mCosine Similarity\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages/pandas/core/frame.py:3896\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3894\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3895\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3896\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3897\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3898\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/CommonLit_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cosine_similarity'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "joined_df['cosine_similarity'].hist(bins=50, grid=False)\n",
    "plt.title('Cosine Similarity Distribution')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_6'></a>\n",
    "### 3.6. Readability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textstat import flesch_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>stopwords_percentage_ratio</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "      <th>prompt_question_readability_score</th>\n",
       "      <th>summary_readability_score</th>\n",
       "      <th>readability_score_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>It happened so fastly because the orig nail ki...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "      <td>[Summarize, how, the, Third, Wave, developed, ...</td>\n",
       "      <td>[The, Third, Wave]</td>\n",
       "      <td>[Background, The, Third, Wave, experiment, too...</td>\n",
       "      <td>[It, happened, so, fastly, because, the, orig,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860937</td>\n",
       "      <td>-0.004218</td>\n",
       "      <td>0.068750</td>\n",
       "      <td>-16.300652</td>\n",
       "      <td>0.359906</td>\n",
       "      <td>0.418750</td>\n",
       "      <td>1.163498</td>\n",
       "      <td>60.65</td>\n",
       "      <td>38.32</td>\n",
       "      <td>0.631822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>In the first paragraph it states that whenever...</td>\n",
       "      <td>0.297031</td>\n",
       "      <td>-0.168734</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[In, the, first, paragraph, it, states, that, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034737</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>-21.111383</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.535557</td>\n",
       "      <td>62.34</td>\n",
       "      <td>67.25</td>\n",
       "      <td>1.078762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>A tragedy should not satisfy your morals, so t...</td>\n",
       "      <td>-0.831253</td>\n",
       "      <td>0.550583</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[A, tragedy, should, not, satisfy, your, moral...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.034668</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>-0.366667</td>\n",
       "      <td>-32.131842</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.858920</td>\n",
       "      <td>58.28</td>\n",
       "      <td>82.95</td>\n",
       "      <td>1.423301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "4267  Summarize how the Third Wave developed over su...   \n",
       "6128  Summarize the various ways the factory would u...   \n",
       "1107  Summarize at least 3 elements of an ideal trag...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "4267           The Third Wave   \n",
       "6128  Excerpt from The Jungle   \n",
       "1107               On Tragedy   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "4267  Background \\r\\nThe Third Wave experiment took ...   \n",
       "6128  With one member trimming beef in a cannery, an...   \n",
       "1107  Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "4267  It happened so fastly because the orig nail ki... -1.547163 -1.461245   \n",
       "6128  In the first paragraph it states that whenever...  0.297031 -0.168734   \n",
       "1107  A tragedy should not satisfy your morals, so t... -0.831253  0.550583   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "4267  [Summarize, how, the, Third, Wave, developed, ...   \n",
       "6128  [Summarize, the, various, ways, the, factory, ...   \n",
       "1107  [Summarize, at, least, 3, elements, of, an, id...   \n",
       "\n",
       "            prompt_title_tokenized  \\\n",
       "4267            [The, Third, Wave]   \n",
       "6128  [Excerpt, from, The, Jungle]   \n",
       "1107                 [On, Tragedy]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "4267  [Background, The, Third, Wave, experiment, too...   \n",
       "6128  [With, one, member, trimming, beef, in, a, can...   \n",
       "1107  [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "4267  [It, happened, so, fastly, because, the, orig,...  ...   \n",
       "6128  [In, the, first, paragraph, it, states, that, ...  ...   \n",
       "1107  [A, tragedy, should, not, satisfy, your, moral...  ...   \n",
       "\n",
       "      stopwords_percentage_ratio  prompt_text_polarity_score  \\\n",
       "4267                    0.860937                   -0.004218   \n",
       "6128                    1.034737                   -0.002368   \n",
       "1107                    1.034668                    0.011411   \n",
       "\n",
       "      summary_polarity_score  polarity_score_ratio  \\\n",
       "4267                0.068750            -16.300652   \n",
       "6128                0.050000            -21.111383   \n",
       "1107               -0.366667            -32.131842   \n",
       "\n",
       "      prompt_text_subjectivity_score  summary_subjectivity_score  \\\n",
       "4267                        0.359906                    0.418750   \n",
       "6128                        0.404563                    0.216667   \n",
       "1107                        0.491573                    0.422222   \n",
       "\n",
       "      subjectivity_score_ratio  prompt_question_readability_score  \\\n",
       "4267                  1.163498                              60.65   \n",
       "6128                  0.535557                              62.34   \n",
       "1107                  0.858920                              58.28   \n",
       "\n",
       "      summary_readability_score  readability_score_ratio  \n",
       "4267                      38.32                 0.631822  \n",
       "6128                      67.25                 1.078762  \n",
       "1107                      82.95                 1.423301  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df['prompt_question_readability_score'] = joined_df['prompt_question'].apply(lambda x: flesch_reading_ease(x))\n",
    "joined_df['summary_readability_score'] = joined_df['summary'].apply(lambda x: flesch_reading_ease(x))\n",
    "joined_df['readability_score_ratio'] = joined_df['summary_readability_score'] / joined_df['prompt_question_readability_score']\n",
    "\n",
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_7'></a>\n",
    "### 3.7. Misspelling frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "sc = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_misspeling_percentage(word_list):\n",
    "\n",
    "    misspelled = sc.unknown(word_list)\n",
    "    percentage_of_misspelled = len(misspelled)/len(word_list)\n",
    "    \n",
    "    return percentage_of_misspelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['summary_misspelled_words_percentage'] = joined_df['summary_tokenized'].apply(lambda x: calculate_misspeling_percentage(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question_tokenized</th>\n",
       "      <th>prompt_title_tokenized</th>\n",
       "      <th>prompt_text_tokenized</th>\n",
       "      <th>summary_tokenized</th>\n",
       "      <th>...</th>\n",
       "      <th>prompt_text_polarity_score</th>\n",
       "      <th>summary_polarity_score</th>\n",
       "      <th>polarity_score_ratio</th>\n",
       "      <th>prompt_text_subjectivity_score</th>\n",
       "      <th>summary_subjectivity_score</th>\n",
       "      <th>subjectivity_score_ratio</th>\n",
       "      <th>prompt_question_readability_score</th>\n",
       "      <th>summary_readability_score</th>\n",
       "      <th>readability_score_ratio</th>\n",
       "      <th>summary_misspelled_words_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "      <td>Tragedy should contain and replicate actions t...</td>\n",
       "      <td>0.050689</td>\n",
       "      <td>0.260165</td>\n",
       "      <td>[Summarize, at, least, 3, elements, of, an, id...</td>\n",
       "      <td>[On, Tragedy]</td>\n",
       "      <td>[Chapter, 13, As, the, sequel, to, what, has, ...</td>\n",
       "      <td>[Tragedy, should, contain, and, replicate, act...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011411</td>\n",
       "      <td>-0.075</td>\n",
       "      <td>-6.572422</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>1.051047</td>\n",
       "      <td>58.28</td>\n",
       "      <td>69.07</td>\n",
       "      <td>1.185141</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5625</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>the meat that was taken out of pickle would o...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[the, meat, that, was, taken, out, of, pickle,...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>63.334149</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.247180</td>\n",
       "      <td>62.34</td>\n",
       "      <td>68.78</td>\n",
       "      <td>1.103304</td>\n",
       "      <td>0.026316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5685</th>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>The factory would take the meat \"out of pickle...</td>\n",
       "      <td>-1.547163</td>\n",
       "      <td>-1.461245</td>\n",
       "      <td>[Summarize, the, various, ways, the, factory, ...</td>\n",
       "      <td>[Excerpt, from, The, Jungle]</td>\n",
       "      <td>[With, one, member, trimming, beef, in, a, can...</td>\n",
       "      <td>[The, factory, would, take, the, meat, ``, out...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002368</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>63.334149</td>\n",
       "      <td>0.404563</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.247180</td>\n",
       "      <td>62.34</td>\n",
       "      <td>76.90</td>\n",
       "      <td>1.233558</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        prompt_question  \\\n",
       "71    Summarize at least 3 elements of an ideal trag...   \n",
       "5625  Summarize the various ways the factory would u...   \n",
       "5685  Summarize the various ways the factory would u...   \n",
       "\n",
       "                 prompt_title  \\\n",
       "71                 On Tragedy   \n",
       "5625  Excerpt from The Jungle   \n",
       "5685  Excerpt from The Jungle   \n",
       "\n",
       "                                            prompt_text  \\\n",
       "71    Chapter 13 \\r\\nAs the sequel to what has alrea...   \n",
       "5625  With one member trimming beef in a cannery, an...   \n",
       "5685  With one member trimming beef in a cannery, an...   \n",
       "\n",
       "                                                summary   content   wording  \\\n",
       "71    Tragedy should contain and replicate actions t...  0.050689  0.260165   \n",
       "5625   the meat that was taken out of pickle would o... -1.547163 -1.461245   \n",
       "5685  The factory would take the meat \"out of pickle... -1.547163 -1.461245   \n",
       "\n",
       "                              prompt_question_tokenized  \\\n",
       "71    [Summarize, at, least, 3, elements, of, an, id...   \n",
       "5625  [Summarize, the, various, ways, the, factory, ...   \n",
       "5685  [Summarize, the, various, ways, the, factory, ...   \n",
       "\n",
       "            prompt_title_tokenized  \\\n",
       "71                   [On, Tragedy]   \n",
       "5625  [Excerpt, from, The, Jungle]   \n",
       "5685  [Excerpt, from, The, Jungle]   \n",
       "\n",
       "                                  prompt_text_tokenized  \\\n",
       "71    [Chapter, 13, As, the, sequel, to, what, has, ...   \n",
       "5625  [With, one, member, trimming, beef, in, a, can...   \n",
       "5685  [With, one, member, trimming, beef, in, a, can...   \n",
       "\n",
       "                                      summary_tokenized  ...  \\\n",
       "71    [Tragedy, should, contain, and, replicate, act...  ...   \n",
       "5625  [the, meat, that, was, taken, out, of, pickle,...  ...   \n",
       "5685  [The, factory, would, take, the, meat, ``, out...  ...   \n",
       "\n",
       "      prompt_text_polarity_score  summary_polarity_score  \\\n",
       "71                      0.011411                  -0.075   \n",
       "5625                   -0.002368                  -0.150   \n",
       "5685                   -0.002368                  -0.150   \n",
       "\n",
       "      polarity_score_ratio  prompt_text_subjectivity_score  \\\n",
       "71               -6.572422                        0.491573   \n",
       "5625             63.334149                        0.404563   \n",
       "5685             63.334149                        0.404563   \n",
       "\n",
       "      summary_subjectivity_score  subjectivity_score_ratio  \\\n",
       "71                      0.516667                  1.051047   \n",
       "5625                    0.100000                  0.247180   \n",
       "5685                    0.100000                  0.247180   \n",
       "\n",
       "      prompt_question_readability_score  summary_readability_score  \\\n",
       "71                                58.28                      69.07   \n",
       "5625                              62.34                      68.78   \n",
       "5685                              62.34                      76.90   \n",
       "\n",
       "      readability_score_ratio  summary_misspelled_words_percentage  \n",
       "71                   1.185141                             0.000000  \n",
       "5625                 1.103304                             0.026316  \n",
       "5685                 1.233558                             0.055556  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_8'></a>\n",
    "### 3.8. Topic overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/duje/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "lem=WordNetLemmatizer()\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.models import LdaModel\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \n",
    "    tokens = pd.Series(text).apply(lambda x: word_tokenize(x))\n",
    "    return tokens\n",
    "\n",
    "def filter_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop and word.isalnum()]\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    \n",
    "    filtered_text = tokens.apply(filter_stopwords)\n",
    "    return filtered_text\n",
    "\n",
    "def remove_special_characters(tokens):\n",
    "    \n",
    "    special_characters = [\".\", \",\", \"!\", \"?\", \":\", \";\", \"'\", '\"', \"(\", \")\", \"[\", \"]\", \"{\", \"}\"]\n",
    "    filtered_text = tokens.apply(lambda x: [word for word in x if word not in special_characters])\n",
    "    return filtered_text\n",
    "\n",
    "def make_lowercase(tokens):\n",
    "    \n",
    "    lowercase_text = tokens.apply(lambda x: [word.lower() for word in x])\n",
    "    return lowercase_text\n",
    "\n",
    "def create_corpus(tokens):\n",
    "    \n",
    "    corpus = [word for sublist in tokens for word in sublist]\n",
    "    return corpus\n",
    "\n",
    "def lemmatize_and_wrap_in_list(corpus):\n",
    "    \n",
    "    infinitives = [[lem.lemmatize(w) for w in corpus]]\n",
    "    return infinitives\n",
    "\n",
    "def create_bow_corpus(dictionary, infinitives):\n",
    "    \n",
    "    bow_corpus = [dictionary.doc2bow(doc) for doc in infinitives]\n",
    "    return bow_corpus\n",
    "\n",
    "def create_lda_model(bow_corpus, num_topics, dictionary, num_passes = 15):\n",
    "    \n",
    "    lda_model = LdaModel(bow_corpus, num_topics=num_topics, id2word=dictionary, passes=num_passes)\n",
    "    return lda_model\n",
    "\n",
    "def extract_topics(lda_model, num_words = 5):\n",
    "    \n",
    "    topics = lda_model.print_topics(num_words=num_words)\n",
    "    return topics\n",
    "\n",
    "def get_topic_words(topics):\n",
    "    \n",
    "    topic_words = \" \".join([\" \".join(re.findall(r'\"([^\"]*)\"', topic[1])) for topic in topics])\n",
    "    return topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_topic_overlap(prompt_question, prompt_text, summary):\n",
    "\n",
    "    num_topics = 3\n",
    "    \n",
    "    #tokenize\n",
    "    prompt_question_tokens = tokenize(prompt_question)\n",
    "    prompt_text_tokens = tokenize(prompt_text)\n",
    "    prompt_summary_tokens = tokenize(summary)\n",
    "    \n",
    "    #remove stopwords\n",
    "    prompt_question_non_stopwords = remove_stopwords(prompt_question_tokens)\n",
    "    prompt_text_non_stopwords = remove_stopwords(prompt_text_tokens)\n",
    "    prompt_summary_non_stopwords = remove_stopwords(prompt_summary_tokens)\n",
    "    \n",
    "    #remove special characters\n",
    "    prompt_question_non_stopwords = remove_special_characters(prompt_question_non_stopwords)\n",
    "    prompt_text_non_stopwords = remove_special_characters(prompt_text_non_stopwords)\n",
    "    prompt_summary_non_stopwords = remove_special_characters(prompt_summary_non_stopwords)  \n",
    "    \n",
    "    #lowercase\n",
    "    prompt_question_non_stopwords = make_lowercase(prompt_question_non_stopwords)\n",
    "    prompt_text_non_stopwords = make_lowercase(prompt_text_non_stopwords)\n",
    "    prompt_summary_non_stopwords = make_lowercase(prompt_summary_non_stopwords)\n",
    "    \n",
    "    #flatten lists to create corpus\n",
    "    prompt_combined_non_stopwords = prompt_question_non_stopwords + prompt_text_non_stopwords\n",
    "    corpus_prompt = create_corpus(prompt_combined_non_stopwords)\n",
    "    corpus_summary = create_corpus(prompt_summary_non_stopwords)\n",
    "    \n",
    "    #lemmatize and wrap in list for gensim (i.e. create list of lists as gensim expects)\n",
    "    infinitives_prompt = lemmatize_and_wrap_in_list(corpus_prompt)\n",
    "    infinitives_summary = lemmatize_and_wrap_in_list(corpus_summary)\n",
    "    \n",
    "    #create dictionary\n",
    "    dictionary_prompt = corpora.Dictionary(infinitives_prompt)\n",
    "    dictionary_summary = corpora.Dictionary(infinitives_summary)\n",
    "    \n",
    "    #create bag of words corpus\n",
    "    bow_corpus_prompt = create_bow_corpus(dictionary_prompt, infinitives_prompt)\n",
    "    bow_corpus_summary = create_bow_corpus(dictionary_summary, infinitives_summary)\n",
    "    \n",
    "    #create LDA model\n",
    "    lda_model_prompt = create_lda_model(bow_corpus_prompt, num_topics, dictionary_prompt)\n",
    "    lda_model_summary = create_lda_model(bow_corpus_summary, num_topics, dictionary_summary)\n",
    "    \n",
    "    #get topics\n",
    "    topics_prompt = extract_topics(lda_model_prompt)\n",
    "    topic_summary = extract_topics(lda_model_summary)\n",
    "    \n",
    "    #get words describing topics and calculate cosine similarity between them\n",
    "    topics_prompt_words = get_topic_words(topics_prompt)\n",
    "    topics_summary_words = get_topic_words(topic_summary)\n",
    "    \n",
    "    topic_overlap = calculate_cosine_similarity(topics_prompt_words, topics_summary_words)\n",
    "    \n",
    "    #return topics_prompt_words, topics_summary_words, topic_overlap\n",
    "    return pd.Series([topics_prompt_words, topics_summary_words, topic_overlap])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[['topics_prompt_words', 'topics_summary_words', 'topic_overlap']] = joined_df.apply(lambda x: calculate_topic_overlap(x['prompt_question'], x['prompt_text'], x['summary']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df['topic_overlap'].hist(bins=50, grid=False)\n",
    "\n",
    "joined_df['cosine_similarity'].hist(bins=50, grid=False, alpha=0.3)\n",
    "plt.xlabel('Cosine Similarity score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(['Topic Overlap', 'Text-Summary Cosine Similarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### [Go to top](#top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3_9'></a>\n",
    "### 3.9. N-gram overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "from word2number import w2n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_words_to_numbers(text):\n",
    "    words = text.split()\n",
    "    converted_words = []\n",
    "\n",
    "    for word in words:\n",
    "        try:\n",
    "            converted_word = str(w2n.word_to_num(word))\n",
    "            converted_words.append(converted_word)\n",
    "        except ValueError:  # word_to_num raises ValueError if it can't convert\n",
    "            converted_words.append(word)\n",
    "\n",
    "    converted_text = ' '.join(converted_words)\n",
    "    return converted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ngram_overlap(prompt_question, prompt_text, summary, top_n=20):\n",
    "    # Tokenize\n",
    "    prompt_question_tokens = tokenize(prompt_question)\n",
    "    prompt_text_tokens = tokenize(prompt_text)\n",
    "    prompt_summary_tokens = tokenize(summary)\n",
    "\n",
    "    # Remove stopwords\n",
    "    prompt_question_non_stopwords = remove_stopwords(prompt_question_tokens)\n",
    "    prompt_text_non_stopwords = remove_stopwords(prompt_text_tokens)\n",
    "    prompt_summary_non_stopwords = remove_stopwords(prompt_summary_tokens)\n",
    "\n",
    "    # Remove special characters\n",
    "    prompt_question_non_stopwords = remove_special_characters(prompt_question_non_stopwords)\n",
    "    prompt_text_non_stopwords = remove_special_characters(prompt_text_non_stopwords)\n",
    "    prompt_summary_non_stopwords = remove_special_characters(prompt_summary_non_stopwords)\n",
    "\n",
    "    # Lowercase\n",
    "    prompt_question_non_stopwords = make_lowercase(prompt_question_non_stopwords)\n",
    "    prompt_text_non_stopwords = make_lowercase(prompt_text_non_stopwords)\n",
    "    prompt_summary_non_stopwords = make_lowercase(prompt_summary_non_stopwords)\n",
    "\n",
    "    # Flatten lists to create corpus\n",
    "    prompt_combined_non_stopwords = prompt_question_non_stopwords + prompt_text_non_stopwords\n",
    "    corpus_prompt = create_corpus(prompt_combined_non_stopwords)\n",
    "    corpus_summary = create_corpus(prompt_summary_non_stopwords)\n",
    "\n",
    "    # Convert numbers to text in the corpus (e.g., 1 -> one)\n",
    "    corpus_prompt = [convert_words_to_numbers(text) for text in corpus_prompt]\n",
    "    corpus_summary = [convert_words_to_numbers(text) for text in corpus_summary]\n",
    "\n",
    "    # Create bigrams and trigrams, and calculate their frequency\n",
    "    bigrams_prompt = ngrams(corpus_prompt, 2)\n",
    "    trigrams_prompt = ngrams(corpus_prompt, 3)\n",
    "    bigrams_summary = ngrams(corpus_summary, 2)\n",
    "    trigrams_summary = ngrams(corpus_summary, 3)\n",
    "\n",
    "    bigrams_prompt_list = [' '.join(bigram) for bigram in bigrams_prompt]\n",
    "    trigrams_prompt_list = [' '.join(trigram) for trigram in trigrams_prompt]\n",
    "    bigrams_summary_list = [' '.join(bigram) for bigram in bigrams_summary]\n",
    "    trigrams_summary_list = [' '.join(trigram) for trigram in trigrams_summary]\n",
    "\n",
    "    # Calculate the frequency of each bigram and trigram in both lists\n",
    "    prompt_bigram_freq = Counter(bigrams_prompt_list)\n",
    "    prompt_trigram_freq = Counter(trigrams_prompt_list)\n",
    "    summary_bigram_freq = Counter(bigrams_summary_list)\n",
    "    summary_trigram_freq = Counter(trigrams_summary_list)\n",
    "\n",
    "    # Calculate the overlap between the two sets of bigrams and trigrams\n",
    "    matching_bigrams = prompt_bigram_freq.keys() & summary_bigram_freq.keys()\n",
    "    matching_trigrams = prompt_trigram_freq.keys() & summary_trigram_freq.keys()\n",
    "\n",
    "    # Calculate the overlap ratios\n",
    "    bigram_overlap_ratio = len(matching_bigrams) / len(prompt_bigram_freq)\n",
    "    trigram_overlap_ratio = len(matching_trigrams) / len(prompt_trigram_freq)\n",
    "\n",
    "    return pd.Series([bigram_overlap_ratio, trigram_overlap_ratio])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df[['bigram_ratio', 'trigram_ratio']] = joined_df.apply(lambda x: calculate_ngram_overlap(x['prompt_question'], x['prompt_text'], x['summary']), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CommonLit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
